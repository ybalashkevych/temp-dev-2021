name: Validation

on:
  pull_request:
    types: [opened, synchronize, reopened]

env:
  SWIFT_ENABLE_EXPERIMENTAL_FEATURES: "0"
  DERIVED_DATA_PATH: DerivedData
  COVERAGE_THRESHOLD: "20.0"

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  build-test-and-coverage:
    name: Build, Test & Coverage
    runs-on: macos-26
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Show Xcode version
        run: xcodebuild -version

      - name: Cache Build Artifacts
        uses: actions/cache@v4
        with:
          path: |
            .build
            DerivedData
            ~/Library/Caches/org.swift.swiftpm
          key: ${{ runner.os }}-xcode-${{ hashFiles('**/Package.resolved') }}
          restore-keys: |
            ${{ runner.os }}-xcode-

      - name: Report cache status
        run: |
          echo "=== SPM Cache Status ==="
          if [ -d "$HOME/Library/Caches/org.swift.swiftpm" ]; then
            du -sh "$HOME/Library/Caches/org.swift.swiftpm" 2>/dev/null || echo "SPM cache exists"
          else
            echo "SPM cache is empty (first run)"
          fi
          if [ -d "DerivedData" ]; then
            du -sh DerivedData 2>/dev/null || echo "DerivedData exists"
          fi
          
      - name: Build and run tests with coverage
        id: test
        run: |
          echo "=== Build Started at $(date) ==="
          xcodebuild test \
            -scheme LiveAssistant \
            -destination 'platform=macOS,arch=arm64' \
            -testPlan LiveAssistant \
            -enableCodeCoverage YES \
            -configuration Debug \
            -derivedDataPath "$DERIVED_DATA_PATH" \
            -skipPackagePluginValidation \
            -skipMacroValidation \
            -parallel-testing-enabled YES \
            CODE_SIGN_IDENTITY="-" \
            CODE_SIGNING_ALLOWED=YES \
            -resultBundlePath TestResults.xcresult 2>&1 | tee test-output.txt || echo "TESTS_FAILED=true" >> $GITHUB_ENV
          echo "=== Build Completed at $(date) ==="

      - name: Extract SwiftLint violations from build
        if: always()
        run: |
          echo "üìù Extracting SwiftLint violations from build output..."
          # Extract SwiftLint violations/warnings from test output
          grep -E "warning:|error:" test-output.txt | head -50 > swiftlint-output.txt 2>/dev/null || true
          
          if [ -s swiftlint-output.txt ]; then
            echo "‚ö†Ô∏è SwiftLint issues found:"
            cat swiftlint-output.txt
          else
            echo "‚úÖ No SwiftLint violations detected"
            echo "No violations detected" > swiftlint-output.txt
          fi

      - name: Generate coverage report
        if: always()
        run: |
          echo "üìä Checking xcresult bundle..."
          ls -lh TestResults.xcresult/ || echo "‚ùå xcresult not found"
          
          # Check if xcresult exists
          if [ ! -d "TestResults.xcresult" ]; then
            echo "0.00" > coverage_result.txt
            echo "FAILED" > coverage_status.txt
            echo "TESTS_FAILED=true" >> $GITHUB_ENV
            echo "‚ö†Ô∏è TestResults.xcresult not found - tests may have failed before completion"
            exit 0
          fi
          
          echo "üìä Generating coverage JSON..."
          if ! xcrun xccov view --report --json TestResults.xcresult > coverage.json 2>&1; then
            echo "0.00" > coverage_result.txt
            echo "FAILED" > coverage_status.txt
            echo "TESTS_FAILED=true" >> $GITHUB_ENV
            echo "‚ö†Ô∏è Failed to generate coverage report"
            exit 0
          fi
          
          echo "üìä Coverage JSON size:"
          ls -lh coverage.json
          
          # Calculate coverage using Python script
          python3 scripts/ci/calculate_coverage.py $COVERAGE_THRESHOLD || true

      - name: Extract test failures
        if: always()
        run: |
          echo "TEST_ERRORS<<EOF" >> $GITHUB_ENV
          if [ "$TESTS_FAILED" == "true" ]; then
            grep -E "error:|failed:|Test Case.*failed" test-output.txt | head -20 || echo "Tests failed but no specific errors captured"
          fi
          echo "EOF" >> $GITHUB_ENV

      - name: Generate PR comment
        if: always()
        run: python3 scripts/ci/report_pr_results.py

      - name: Comment on PR
        uses: actions/github-script@v7
        if: always() && hashFiles('pr-comment.md') != ''
        with:
          script: |
            const fs = require('fs');
            
            // Check if comment file exists
            if (!fs.existsSync('pr-comment.md')) {
              console.log('‚ö†Ô∏è pr-comment.md not found, skipping PR comment');
              return;
            }
            
            const comment = fs.readFileSync('pr-comment.md', 'utf8');
            
            // Find existing bot comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && c.body.includes('PR Validation Results')
            );
            
            if (botComment) {
              console.log(`Updating existing comment ${botComment.id}`);
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              console.log('Creating new comment');
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Upload test results and coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-and-coverage-results
          path: |
            TestResults.xcresult
            coverage.json
            coverage_result.txt
            test-output.txt
          retention-days: 7

      - name: Check final status
        run: |
          COVERAGE_STATUS=$(cat coverage_status.txt 2>/dev/null || echo "UNKNOWN")
          
          if [ "$TESTS_FAILED" == "true" ]; then
            echo "‚ùå Tests failed"
            exit 1
          fi
          
          if [ "$COVERAGE_STATUS" == "FAILED" ]; then
            COVERAGE=$(cat coverage_result.txt)
            echo "‚ùå Coverage $COVERAGE% is below threshold $COVERAGE_THRESHOLD%"
            exit 1
          fi
          
          echo "‚úÖ All checks passed"
